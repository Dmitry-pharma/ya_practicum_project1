import torch
from tqdm import tqdm
from sklearn.metrics import accuracy_score
from collections import Counter
import random
import evaluate  # pip install evaluate
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def vevaluate(model, loader, criterion, device, tokenizer, compute_rouge=False, num_rouge_examples=50):
    model.eval()
    preds, trues = [], []
    total_loss = 0
    # –î–ª—è ROUGE –º–µ—Ç—Ä–∏–∫
    references,predictions = [],[]
    
    with torch.no_grad():
        examples_processed = 0
        for batch in loader:
            ids = batch['data'].to(device)
            mask = batch['mask'].to(device)
            labels = batch['target'].to(device)
            
            logits = model(ids, mask)
            logits_flat = logits.reshape(-1, logits.size(-1))
            labels_flat = labels.reshape(-1)
            
            loss = criterion(logits_flat, labels_flat)
            total_loss += loss.item()
            
            batch_preds = torch.argmax(logits, dim=-1)
            
            # preds += torch.argmax(logits, dim=-1).cpu().flatten().tolist()
            preds += batch_preds.cpu().flatten().tolist()
            trues += labels.cpu().flatten().tolist()
             # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è ROUGE
            if compute_rouge and examples_processed < num_rouge_examples:
                for i in range(ids.size(0)):
                    if examples_processed >= num_rouge_examples:
                        break
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–∞–¥–¥–∏–Ω–≥)
                    non_pad_indices = mask[i].bool()
                    if non_pad_indices.sum() == 0:
                        continue
                    
                    input_ids_real = ids[i][non_pad_indices]
                    preds_real = batch_preds[i][non_pad_indices]
                    labels_real = labels[i][non_pad_indices]
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç
                    try:
                        # –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç (–∫–æ–Ω—Ç–µ–∫—Å—Ç)
                        input_tokens = tokenizer.convert_ids_to_tokens(input_ids_real.cpu())
                        input_text = tokenizer.convert_tokens_to_string(input_tokens)
                        
                        # –¶–µ–ª–µ–≤–æ–π —Ç–µ–∫—Å—Ç (–æ–∂–∏–¥–∞–µ–º–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)
                        true_tokens = tokenizer.convert_ids_to_tokens(labels_real.cpu())
                        true_text = tokenizer.convert_tokens_to_string(true_tokens)
                        
                        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                        pred_tokens = tokenizer.convert_ids_to_tokens(preds_real.cpu())
                        pred_text = tokenizer.convert_tokens_to_string(pred_tokens)
                        
                        # –î–ª—è –∑–∞–¥–∞—á–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
                        # Reference - –æ–∂–∏–¥–∞–µ–º–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ, Prediction - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
                        if true_text.strip() and pred_text.strip():
                            references.append(true_text)
                            predictions.append(pred_text)
                            examples_processed += 1
                            
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è ROUGE: {e}")
                        continue
    
    accuracy = accuracy_score(trues, preds)
    avg_loss = total_loss / len(loader)
    # –í—ã—á–∏—Å–ª—è–µ–º ROUGE –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    rouge_metrics = None
    if compute_rouge and references and predictions:
        try:
            rouge = evaluate.load('rouge')
            rouge_results = rouge.compute(
                predictions=predictions,
                references=references,
                use_stemmer=True,
                use_aggregator=True
            )
            
            rouge_metrics = {
                'rouge1': round(rouge_results['rouge1'], 4),
                'rouge2': round(rouge_results['rouge2'], 4),
                'rougeL': round(rouge_results['rougeL'], 4),
                'rougeLsum': round(rouge_results['rougeLsum'], 4),
                'num_examples': len(references)
            }
            
            # print(f"üìä ROUGE –º–µ—Ç—Ä–∏–∫–∏ ({len(references)} –ø—Ä–∏–º–µ—Ä–æ–≤):")
            # print(f"   ROUGE-1: {rouge_metrics['rouge1']:.4f}")
            # print(f"   ROUGE-2: {rouge_metrics['rouge2']:.4f}")
            # print(f"   ROUGE-L: {rouge_metrics['rougeL']:.4f}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ ROUGE: {e}")
            rouge_metrics = {'error': str(e)}
    return accuracy, avg_loss, rouge_metrics

def vevaluate2(model, loader, criterion, device, tokenizer, compute_rouge=False, num_rouge_examples=50):
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º accuracy, loss –∏ ROUGE –º–µ—Ç—Ä–∏–∫
    
    Args:
        model: –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        loader: DataLoader —Å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        criterion: —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (cpu/cuda)
        tokenizer: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        compute_rouge: –≤—ã—á–∏—Å–ª—è—Ç—å ROUGE –º–µ—Ç—Ä–∏–∫–∏
        num_rouge_examples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è ROUGE
    
    Returns:
        accuracy, avg_loss, rouge_metrics
    """
    model.eval()
    preds, trues = [], []
    total_loss = 0
    references, predictions = [], []
    
    with torch.no_grad():
        examples_processed = 0
        
        for batch_idx, batch in enumerate(loader):
            ids = batch['data'].to(device)
            mask = batch['mask'].to(device)
            labels = batch['target'].to(device)
            
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            logits = model(ids, mask)
            logits_flat = logits.reshape(-1, logits.size(-1))
            labels_flat = labels.reshape(-1)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
            loss = criterion(logits_flat, labels_flat)
            total_loss += loss.item()
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            batch_preds = torch.argmax(logits, dim=-1)
            
            # –°–±–æ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–ò–°–ö–õ–Æ–ß–ê–Ø PAD –¢–û–ö–ï–ù–´)
            non_pad_mask = (labels != tokenizer.pad_token_id)
            preds_non_pad = batch_preds[non_pad_mask].cpu().flatten().tolist()
            trues_non_pad = labels[non_pad_mask].cpu().flatten().tolist()
            
            preds.extend(preds_non_pad)
            trues.extend(trues_non_pad)
            
            # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ROUGE
            if compute_rouge and examples_processed < num_rouge_examples:
                batch_size = ids.size(0)
                
                for i in range(batch_size):
                    if examples_processed >= num_rouge_examples:
                        break
                    
                    try:
                        # –ù–∞—Ö–æ–¥–∏–º –≥—Ä–∞–Ω–∏—Ü—É –º–µ–∂–¥—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º
                        non_pad_indices = mask[i].bool()
                        if non_pad_indices.sum() == 0:
                            continue
                            
                        # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ç–æ–∫–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–∏–π –≤ –ø–æ–ª–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
                        context_end_idx = non_pad_indices.sum().item() - 1
                        if context_end_idx <= 0:
                            continue
                        
                        # –ö–æ–Ω—Ç–µ–∫—Å—Ç (–≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
                        context_tokens = ids[i][:context_end_idx]
                        context_text = tokenizer.decode(context_tokens.cpu(), skip_special_tokens=True)
                        
                        # –û–∂–∏–¥–∞–µ–º–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–æ–∫–µ–Ω)
                        expected_next_token = labels[i][context_end_idx]
                        expected_text = tokenizer.decode([expected_next_token.item()], skip_special_tokens=True)
                        
                        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
                        predicted_next_token = batch_preds[i][context_end_idx]
                        predicted_text = tokenizer.decode([predicted_next_token.item()], skip_special_tokens=True)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–µ–∫—Å—Ç—ã –Ω–µ –ø—É—Å—Ç—ã–µ
                        if expected_text.strip() and predicted_text.strip():
                            references.append(expected_text)
                            predictions.append(predicted_text)
                            examples_processed += 1
                            
                            # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                            # if examples_processed == 1:
                            #     print(f"üîç –ü—Ä–∏–º–µ—Ä ROUGE:")
                            #     print(f"   –ö–æ–Ω—Ç–µ–∫—Å—Ç: '{context_text}'")
                            #     print(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: '{expected_text}'")
                            #     print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: '{predicted_text}'")
                            
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–∏–º–µ—Ä–∞ {examples_processed} –¥–ª—è ROUGE: {e}")
                        continue
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ accuracy (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ-pad —Ç–æ–∫–µ–Ω–æ–≤)
    accuracy = accuracy_score(trues, preds) if trues and preds else 0.0
    avg_loss = total_loss / len(loader)
    
    # ROUGE –º–µ—Ç—Ä–∏–∫–∏
    rouge_metrics = None
    if compute_rouge and references and predictions:
        try:
            rouge = evaluate.load('rouge')
            rouge_results = rouge.compute(
                predictions=predictions,
                references=references,
                use_stemmer=True,
                use_aggregator=True
            )
            
            rouge_metrics = {
                'rouge1': round(rouge_results['rouge1'], 4),
                'rouge2': round(rouge_results['rouge2'], 4),
                'rougeL': round(rouge_results['rougeL'], 4),
                'rougeLsum': round(rouge_results['rougeLsum'], 4),
                'num_examples': len(references)
            }
            
            # print(f"üìä ROUGE –º–µ—Ç—Ä–∏–∫–∏ ({len(references)} –ø—Ä–∏–º–µ—Ä–æ–≤):")
            # print(f"   ROUGE-1: {rouge_metrics['rouge1']:.4f}")
            # print(f"   ROUGE-2: {rouge_metrics['rouge2']:.4f}")
            # print(f"   ROUGE-L: {rouge_metrics['rougeL']:.4f}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ ROUGE: {e}")
            rouge_metrics = {'error': str(e)}
    elif compute_rouge:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å ROUGE: –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
        rouge_metrics = {'error': 'No valid examples'}
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"üìä –í–∞–ª–∏–¥–∞—Ü–∏—è: Accuracy={accuracy:.4f}, Loss={avg_loss:.4f}, "
          f"–ü—Ä–∏–º–µ—Ä–æ–≤={len(preds)}, ROUGE –ø—Ä–∏–º–µ—Ä–æ–≤={len(references) if references else 0}")
    
    return accuracy, avg_loss, rouge_metrics

def vevaluate3(model, loader, criterion, device, tokenizer, compute_rouge=False, num_rouge_examples=50):
    model.eval()
    preds, trues = [], []
    total_loss = 0
    total_tokens = 0  # ‚Üê –î–û–ë–ê–í–õ–ï–ù–û: —Å—á–µ—Ç—á–∏–∫ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    # –î–ª—è ROUGE –º–µ—Ç—Ä–∏–∫
    references,predictions = [],[]
    
    with torch.no_grad():
        examples_processed = 0
        for batch in loader:
            ids = batch['data'].to(device)
            mask = batch['mask'].to(device)
            labels = batch['target'].to(device)
            
            logits = model(ids, mask)
            
            logits_flat = logits.reshape(-1, logits.size(-1))
            labels_flat = labels.reshape(-1)
            
            #!!! –°–æ–∑–¥–∞–µ–º mask –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è pad-—Ç–æ–∫–µ–Ω–æ–≤
            loss_mask = (labels_flat != tokenizer.pad_token_id)
            if loss_mask.sum() == 0:  # –µ—Å–ª–∏ –≤ –±–∞—Ç—á–µ —Ç–æ–ª—å–∫–æ pad-—Ç–æ–∫–µ–Ω—ã
                continue
            #!!! –ü—Ä–∏–º–µ–Ω—è–µ–º mask
            logits_masked = logits_flat[loss_mask]
            labels_masked = labels_flat[loss_mask]
            
            #!!! –°—á–∏—Ç–∞–µ–º loss —Ç–æ–ª—å–∫–æ –ø–æ —Ä–µ–∞–ª—å–Ω—ã–º —Ç–æ–∫–µ–Ω–∞–º
            loss = criterion(logits_masked, labels_masked)
            total_loss += loss.item() * loss_mask.sum().item()  # –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π loss
            total_tokens += loss_mask.sum().item()  # –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
            
            # loss = criterion(logits_flat, labels_flat)
            # total_loss += loss.item()
            
            batch_preds = torch.argmax(logits, dim=-1)
            #!!!–¥–æ–±–∞–≤–ª–µ–Ω–æ
            non_pad_mask = (labels != tokenizer.pad_token_id)
            
            # preds += torch.argmax(logits, dim=-1).cpu().flatten().tolist()
            # preds += batch_preds.cpu().flatten().tolist()
            # trues += labels.cpu().flatten().tolist()
            
            #!!!–¥–æ–±–∞–≤–ª–µ–Ω–æ
            preds_non_pad = batch_preds[non_pad_mask].cpu().tolist()
            trues_non_pad = labels[non_pad_mask].cpu().tolist()            
            preds.extend(preds_non_pad)
            trues.extend(trues_non_pad)
            
             # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è ROUGE
            if compute_rouge and examples_processed < num_rouge_examples:
                for i in range(ids.size(0)):
                    if examples_processed >= num_rouge_examples:
                        break
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–∞–¥–¥–∏–Ω–≥)
                    non_pad_indices = mask[i].bool()
                    if non_pad_indices.sum() == 0:
                        continue
                    
                    input_ids_real = ids[i][non_pad_indices]
                    preds_real = batch_preds[i][non_pad_indices]
                    labels_real = labels[i][non_pad_indices]
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç
                    try:
                        # –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç (–∫–æ–Ω—Ç–µ–∫—Å—Ç)
                        input_tokens = tokenizer.convert_ids_to_tokens(input_ids_real.cpu())
                        input_text = tokenizer.convert_tokens_to_string(input_tokens)
                        
                        # –¶–µ–ª–µ–≤–æ–π —Ç–µ–∫—Å—Ç (–æ–∂–∏–¥–∞–µ–º–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ)
                        true_tokens = tokenizer.convert_ids_to_tokens(labels_real.cpu())
                        true_text = tokenizer.convert_tokens_to_string(true_tokens)
                        
                        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                        pred_tokens = tokenizer.convert_ids_to_tokens(preds_real.cpu())
                        pred_text = tokenizer.convert_tokens_to_string(pred_tokens)
                        
                        # –î–ª—è –∑–∞–¥–∞—á–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
                        # Reference - –æ–∂–∏–¥–∞–µ–º–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ, Prediction - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
                        if true_text.strip() and pred_text.strip():
                            references.append(true_text)
                            predictions.append(pred_text)
                            examples_processed += 1
                            
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–ª—è ROUGE: {e}")
                        continue
    
    # accuracy = accuracy_score(trues, preds)
    # avg_loss = total_loss / len(loader)
    #!!!!–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
    avg_loss = total_loss / total_tokens if total_tokens > 0 else float('inf')
    accuracy = accuracy_score(trues, preds) if trues and preds else 0.0
    # –í—ã—á–∏—Å–ª—è–µ–º ROUGE –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    rouge_metrics = None
    if compute_rouge and references and predictions:
        try:
            rouge = evaluate.load('rouge')
            rouge_results = rouge.compute(
                predictions=predictions,
                references=references,
                use_stemmer=True,
                use_aggregator=True
            )
            
            rouge_metrics = {
                'rouge1': round(rouge_results['rouge1'], 4),
                'rouge2': round(rouge_results['rouge2'], 4),
                'rougeL': round(rouge_results['rougeL'], 4),
                'rougeLsum': round(rouge_results['rougeLsum'], 4),
                'num_examples': len(references)
            }
            
            # print(f"üìä ROUGE –º–µ—Ç—Ä–∏–∫–∏ ({len(references)} –ø—Ä–∏–º–µ—Ä–æ–≤):")
            # print(f"   ROUGE-1: {rouge_metrics['rouge1']:.4f}")
            # print(f"   ROUGE-2: {rouge_metrics['rouge2']:.4f}")
            # print(f"   ROUGE-L: {rouge_metrics['rougeL']:.4f}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ ROUGE: {e}")
            rouge_metrics = {'error': str(e)}
    return accuracy, avg_loss, rouge_metrics


def test_model(model, loader, criterion, device):
    model.eval()
    all_preds, all_trues = [], []
    test_loss = 0
    
    with torch.no_grad():
        for batch in tqdm(loader, desc="Testing"):
            ids = batch['data'].to(device)
            mask = batch['mask'].to(device)
            labels = batch['target'].to(device)
            
            logits = model(ids, mask)
            logits_flat = logits.reshape(-1, logits.size(-1))
            labels_flat = labels.reshape(-1)
            
            loss = criterion(logits_flat, labels_flat)
            test_loss += loss.item()
            
            preds = torch.argmax(logits, dim=-1)
            all_preds.extend(preds.cpu().flatten().tolist())
            all_trues.extend(labels.cpu().flatten().tolist())
    
    accuracy = accuracy_score(all_trues, all_preds)
    avg_loss = test_loss / len(loader)
    
    print(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"   Test Loss: {avg_loss:.4f}")
    print(f"   Test Accuracy: {accuracy:.4f}")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(all_trues)}")
    
    return accuracy, avg_loss

def analyze_predictions(model, loader, tokenizer, device, num_examples=5):
    model.eval()
    bad_cases, good_cases = [], []
    
    with torch.no_grad():
        for batch in loader:
            ids = batch['data'].to(device)
            mask = batch['mask'].to(device)
            labels = batch['target'].to(device)
            
            logits = model(ids, mask)
            preds = torch.argmax(logits, dim=-1)
            
            for i in range(ids.size(0)):
                non_pad_indices = mask[i].bool()
                if non_pad_indices.sum() == 0:
                    continue
                
                input_ids_real = ids[i][non_pad_indices]
                preds_real = preds[i][non_pad_indices]
                labels_real = labels[i][non_pad_indices]
                
                input_tokens = tokenizer.convert_ids_to_tokens(input_ids_real.cpu())
                true_tokens = tokenizer.convert_ids_to_tokens(labels_real.cpu())
                pred_tokens = tokenizer.convert_ids_to_tokens(preds_real.cpu())
                
                min_length = min(len(input_tokens)-1, len(true_tokens), len(pred_tokens))
                
                for j in range(min_length):
                    if j >= len(true_tokens) or j >= len(pred_tokens):
                        continue
                        
                    context = input_tokens[:j+1]
                    true_tok = true_tokens[j]
                    pred_tok = pred_tokens[j]
                    
                    skip_tokens = ['[PAD]', '[CLS]', '[SEP]', '<pad>', '<cls>', '<sep>', '']
                    if true_tok in skip_tokens or pred_tok in skip_tokens:
                        continue
                    if true_tok == pred_tok and true_tok in skip_tokens:
                        continue
                    
                    if true_tok != pred_tok:
                        bad_cases.append((context, true_tok, pred_tok))
                    else:
                        good_cases.append((context, true_tok, pred_tok))
            
            if len(bad_cases) > 200 and len(good_cases) > 200:
                break
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –ø–æ–∫–∞–∑–∞
    if not bad_cases and not good_cases:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("   - –í—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ")
        print("   - –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π")
        print("   - –°–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤")
        return [], []
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    random.seed(42)
    
    # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π sampling —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏
    bad_cases_sampled = []
    good_cases_sampled = []
    
    if bad_cases:
        bad_cases_sampled = random.sample(bad_cases, min(num_examples, len(bad_cases)))
    if good_cases:
        good_cases_sampled = random.sample(good_cases, min(num_examples, len(good_cases)))
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "="*60)
    print("üîç –ê–ù–ê–õ–ò–ó –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô –ù–ê –¢–ï–°–¢–û–í–û–ô –í–´–ë–û–†–ö–ï")
    print("="*60)
    
    if bad_cases_sampled:
        print(f"\n‚ùå –ü—Ä–∏–º–µ—Ä—ã –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–• –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ({len(bad_cases_sampled)} –∏–∑ {len(bad_cases)}):")
        print("-" * 50)
        for i, (context, true_tok, pred_tok) in enumerate(bad_cases_sampled, 1):
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Ç–æ–∫–µ–Ω–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–∏–ª–∏ –≤—Å–µ –µ—Å–ª–∏ –º–µ–Ω—å—à–µ)
            context_to_show = context[-5:] if len(context) > 5 else context
            context_str = ' '.join(context_to_show)
            
            print(f"{i}. –ö–æ–Ω—Ç–µ–∫—Å—Ç: ...{context_str}")
            print(f"   –ò—Å—Ç–∏–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω: '{true_tok}' | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π: '{pred_tok}'")
            print(f"   –°—Ç–∞—Ç—É—Å: {'üö´ –û–®–ò–ë–ö–ê' if true_tok != pred_tok else '‚úÖ –í–ï–†–ù–û'}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–∞—Ö
            true_len = len(true_tok)
            pred_len = len(pred_tok)
            if true_len != pred_len:
                print(f"   –†–∞–∑–Ω–∏—Ü–∞ –¥–ª–∏–Ω—ã: {true_len} vs {pred_len}")
            print()
    else:
        print(f"\n‚úÖ –ù–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –ø–æ–∫–∞–∑–∞!")
    
    if good_cases_sampled:
        print(f"\n‚úÖ –ü—Ä–∏–º–µ—Ä—ã –ü–†–ê–í–ò–õ–¨–ù–´–• –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ({len(good_cases_sampled)} –∏–∑ {len(good_cases)}):")
        print("-" * 50)
        for i, (context, true_tok, pred_tok) in enumerate(good_cases_sampled, 1):
            context_to_show = context[-5:] if len(context) > 5 else context
            context_str = ' '.join(context_to_show)
            
            print(f"{i}. –ö–æ–Ω—Ç–µ–∫—Å—Ç: ...{context_str}")
            print(f"   –ò—Å—Ç–∏–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω: '{true_tok}' | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π: '{pred_tok}'")
            print(f"   –°—Ç–∞—Ç—É—Å: {'‚úÖ –í–ï–†–ù–û' if true_tok == pred_tok else 'üö´ –û–®–ò–ë–ö–ê'}")
            print()
    else:
        print(f"\n‚ùå –ù–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –ø–æ–∫–∞–∑–∞!")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_predictions = len(bad_cases) + len(good_cases)
    if total_predictions > 0:
        accuracy = len(good_cases) / total_predictions * 100
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:")
        print(f"   –í—Å–µ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {total_predictions}")
        print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {len(good_cases)} ({accuracy:.2f}%)")
        print(f"   –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {len(bad_cases)} ({100-accuracy:.2f}%)")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if bad_cases:
            avg_context_length = sum(len(context) for context, _, _ in bad_cases) / len(bad_cases)
            print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö: {avg_context_length:.1f} —Ç–æ–∫–µ–Ω–æ–≤")
    else:
        print(f"\nüìä –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    
    return bad_cases, good_cases

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
 
def show_detailed_examples(model, test_loader, tokenizer, num_examples=3):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏"""
    model.eval()
    
    print("\n" + "="*60)
    print("üî¨ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ê–ë–û–¢–´ –ú–û–î–ï–õ–ò")
    print("="*60)
    
    examples_shown = 0
    with torch.no_grad():
        for batch in test_loader:
            if examples_shown >= num_examples:
                break
                
            ids = batch['data'].to(device)
            mask = batch['mask'].to(device)
            labels = batch['target'].to(device)
            
            logits = model(ids, mask)
            preds = torch.argmax(logits, dim=-1)
            
            for i in range(min(num_examples - examples_shown, ids.size(0))):
                print(f"\nüìù –ü—Ä–∏–º–µ—Ä {examples_shown + 1}:")
                print("-" * 40)
                
                # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–Ω—É–ª–µ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã
                non_pad_indices = mask[i].bool()
                input_ids_real = ids[i][non_pad_indices]
                preds_real = preds[i][non_pad_indices]
                labels_real = labels[i][non_pad_indices]
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç
                input_tokens = tokenizer.convert_ids_to_tokens(input_ids_real.cpu())
                input_text = tokenizer.convert_tokens_to_string(input_tokens)
                
                true_tokens = tokenizer.convert_ids_to_tokens(labels_real.cpu())
                true_text = tokenizer.convert_tokens_to_string(true_tokens)
                
                pred_tokens = tokenizer.convert_ids_to_tokens(preds_real.cpu())
                pred_text = tokenizer.convert_tokens_to_string(pred_tokens)
                
                print(f"–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç: {input_text}")
                print(f"–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥: {true_text}")
                print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥: {pred_text}")
                
                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º
                print("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Ç–æ–∫–µ–Ω–∞–º:")
                min_len = min(len(true_tokens), len(pred_tokens))
                for j in range(min_len):
                    status = "‚úÖ" if true_tokens[j] == pred_tokens[j] else "‚ùå"
                    print(f"  {status} –ü–æ–∑–∏—Ü–∏—è {j}: '{true_tokens[j]}' vs '{pred_tokens[j]}'")
                
                examples_shown += 1
                print()

def analyze_error_patterns(bad_cases, tokenizer):
    if not bad_cases:
        print("–ù–µ—Ç –æ—à–∏–±–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞! üéâ")
        return
    
    error_pairs = [(true, pred) for _, true, pred in bad_cases]
    error_counter = Counter(error_pairs)
    
    print("\nüîù –¢–æ–ø-10 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–æ–∫:")
    for (true_tok, pred_tok), count in error_counter.most_common(10):
        print(f"  '{true_tok}' ‚Üí '{pred_tok}': {count} —Ä–∞–∑")
    
    length_errors = [abs(len(true_tok) - len(pred_tok)) for _, true_tok, pred_tok in bad_cases]
    if length_errors:
        avg_length_diff = sum(length_errors) / len(length_errors)
        print(f"\nüìè –°—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –¥–ª–∏–Ω–µ —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö: {avg_length_diff:.2f}")