# ya_practicum_project1
sprint 2 final project

Цель проекта: 
сравнить эффективность локально обученной реккурентной сети и модели трансформера по задаче next phrase generation и предложить наиболее эффективный вариант для бизнес-приложения

Задачи проекта:
1) сформировать очищенный датасет на основе сообщений твитера, подготовить выборки (трейн: 80%, валидация: 10%, тест: 10%)
2) создать и обучить реккурентную нейронную сеть (LSTM) на основе датасета
3) сравнить эффективность моделей
4) сформировать выводы и предложения по выбору наилучшей модели (LSTM vs distilgpt2)

Структура проекта:
ya_practicum_project1/
├── data/                            # Датасеты
│   ├── 1_raw_dataset_tweets.txt     # "сырой" скачанный датасет
│   └── 2_cleaned_dataset_tweets.csv # "очищенный" датасет, для отладки содержит raw_text и cleaned text
│
├── src/                             # Весь код проекта
│   ├── data_utils.py                # Обработка датасета
|   ├── next_token_dataset.py        # код с torch Dataset'ом 
│   ├── lstm_model.py                # код lstm модели
|   ├── eval_lstm.py                 # замер метрик lstm модели
|   ├── lstm_train.py                # код обучения модели
|   ├── eval_transformer_pipeline.py # код с запуском и замером качества трансформера
|   ├── visualization.py             # код визуализации - подготовка графиков результатов обучения
│   ├── test_models.py               #
│   └── test_models_table.py         #
│
├── models/                          # веса обученных моделей
|
├── results/                         # итоги сравнения
│
├── solution.ipynb                   # ноутбук с решением
└── requirements.txt                 # зависимости проекта 

Описание реккурентной модели
модель может работать в 3х режимах: RNN, LSTM, GRU. Результаты приведены для модели LSTM как наилучшие
размерность скрытого слоя = 512
в модели использовались:
- слой нормализации (nn.LayerNorm())
- слой регуляризации (nn.Dropout())
- инициализация весов (xavier_uniform)
<img width="1589" height="990" alt="image" src="https://github.com/user-attachments/assets/c9fc87ca-cbcc-439f-98af-5a274ec5bf2c" />

Описание модели distilgpt
модель запускалась на генерацию с параметрами:


Формулирование выводов
Проведено сравнение двух результатов: по метрикам и вручную по примерам предсказаний.
Сделаны осмысленные выводы, какая модель лучше (либо значительно лучше по метрике, либо очевидно лучше генерирует дополнения). Даны рекомендации, что лучше использовать. Если есть явный фаворит — замерено финальное качество на тестовом датасете и отдельно приведены примеры его предсказаний.
