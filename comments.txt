Артем, привет.

сразу приношу извинения за код, это мой первый опыт, до этого не приходилось организовывать много кода в одном месте. и я пока не понял как быть с версионностью, поэтому так много функций с числами.
заранее спасибо за твои комментарии!
Я действительно хочу разобраться в работе RNN, поэтому любые твои комментарии будут уместны. Прошу подсказать, что я делал неправильно и как бы ты поступил на моем месте).

Отвечаю по твоим комментариям:
1.из data_utils.py - удалил ненужный код, все комментарии были в нем. Еще раз приношу извинения, ценю твое время, я думал будет только запуск кода со стороны ревьюера, а не вычитывание.
2.eval_lstm.py - точно также, только vevaluate3 из всего "семейства" vevaluate актуальная, убрал лишнее, оставил необходимое
3. lstm_model.py - точно также, убрал не используемый код
4. lstm_train.py - по сути весь код используется в ./solution.ipynb, тогда лучше удалить этот файл(lstm_train.py)?



По моим вопросам:

1. пожалуйста посмотри, правильно ли я формирую Y и оцениваю результат. Мое сомнение в том, что обычно в интернете рекомендуют оставлять не смещение на 1 токен, а только один следующий токен. Я придерживался условий задания, поэтому формировал Y со смещением от X на один токен.

2. Посмотри пожалуйста графики обучения в файле ./results/results.docx, там ты увидишь, что результаты получились намного хуже. Можно попросить тебя оставить короткие комментарии, там где это необходимо, что ты видишь на графике и в каком направлении двигаться при такой картинке.

3. У меня не получилось достичь непрерывного снижения val loss, в определенный момент, он начинает расти при продолжающемся снижении train loss, что нужно делать в этом случае? как ты считаешь почему так происходит? 
Что я пытался сделать в этой ситуации: снижал скорость обучения с 0.001 до 0.0001, снизил длину фразы (с 20 токенов до 10) и увеличил выборку. Немного поигрался с weight_decay=0.01 - 0.001 , nn.Dropout(0.5-0.7).Что еще можно было попробовать?

4. Meaning pooling рекомендован в курсе, но в данном случае только ухудшал обучение. Градиент клиппинг (последний график в вордовском документе) - привел к снижению Val loss, но посмотри пожалуйста насколько это здоровая картинка. Было установлено 200 эпох и patience - останов на 50 эпох без улучшения, в итоге модель остановила обучение где-то в районе 170 эпохи, т.е. незначительные улучшения были несмотря, что график выходит на плато.

5. возможно глупый вопрос, но я не понял с соотношением размера батча, количества эпох и размера выборки для обучения и валидации. 
Если у меня обучающий датасет на 30000 пар X/Y, валидационный получился на 4000 пар. Правильно ли я понимаю, что на 117 эпохе обучающая выборка закончится (30тыс./256 размер батча = 117 циклов)? Что тогда произойдет с валидационной, которая меньше (в одной эпохе мы используем один обучающий батч и один валидационный)? 

